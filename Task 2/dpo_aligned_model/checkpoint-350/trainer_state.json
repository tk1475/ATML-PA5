{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9333333333333333,
  "eval_steps": 500,
  "global_step": 350,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 2.113584041595459,
      "learning_rate": 4.8571428571428576e-05,
      "logits/chosen": 1.7563155889511108,
      "logits/rejected": 2.026265859603882,
      "logps/chosen": -240.8377227783203,
      "logps/rejected": -316.6041259765625,
      "loss": 0.668,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.0010694540105760098,
      "rewards/margins": 0.051688484847545624,
      "rewards/rejected": -0.05275794118642807,
      "step": 10
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 1.8436768054962158,
      "learning_rate": 4.714285714285714e-05,
      "logits/chosen": 2.454881429672241,
      "logits/rejected": 2.5419821739196777,
      "logps/chosen": -295.6739807128906,
      "logps/rejected": -326.0164794921875,
      "loss": 0.6076,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -0.035120636224746704,
      "rewards/margins": 0.18238934874534607,
      "rewards/rejected": -0.21750995516777039,
      "step": 20
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.971117377281189,
      "learning_rate": 4.5714285714285716e-05,
      "logits/chosen": 2.227987766265869,
      "logits/rejected": 2.573942184448242,
      "logps/chosen": -267.542236328125,
      "logps/rejected": -306.62249755859375,
      "loss": 0.5475,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -0.054930828511714935,
      "rewards/margins": 0.3306940197944641,
      "rewards/rejected": -0.38562482595443726,
      "step": 30
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 1.7863010168075562,
      "learning_rate": 4.428571428571428e-05,
      "logits/chosen": 1.9934841394424438,
      "logits/rejected": 2.4600613117218018,
      "logps/chosen": -258.02459716796875,
      "logps/rejected": -315.60235595703125,
      "loss": 0.5014,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -0.10689039528369904,
      "rewards/margins": 0.462557315826416,
      "rewards/rejected": -0.5694476962089539,
      "step": 40
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 1.4844295978546143,
      "learning_rate": 4.2857142857142856e-05,
      "logits/chosen": 2.171372890472412,
      "logits/rejected": 2.5542221069335938,
      "logps/chosen": -219.0178680419922,
      "logps/rejected": -283.20550537109375,
      "loss": 0.4561,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -0.14162613451480865,
      "rewards/margins": 0.5937538743019104,
      "rewards/rejected": -0.7353800535202026,
      "step": 50
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.871455430984497,
      "learning_rate": 4.1571428571428575e-05,
      "logits/chosen": 2.348707675933838,
      "logits/rejected": 2.9204025268554688,
      "logps/chosen": -289.49053955078125,
      "logps/rejected": -321.0801696777344,
      "loss": 0.388,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -0.2466084063053131,
      "rewards/margins": 0.8387414216995239,
      "rewards/rejected": -1.0853497982025146,
      "step": 60
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 1.5920461416244507,
      "learning_rate": 4.014285714285714e-05,
      "logits/chosen": 2.4842381477355957,
      "logits/rejected": 2.7501907348632812,
      "logps/chosen": -289.0506896972656,
      "logps/rejected": -316.41680908203125,
      "loss": 0.3491,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -0.3077264428138733,
      "rewards/margins": 1.05722177028656,
      "rewards/rejected": -1.3649481534957886,
      "step": 70
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 1.1898220777511597,
      "learning_rate": 3.8714285714285715e-05,
      "logits/chosen": 2.02815318107605,
      "logits/rejected": 2.521968364715576,
      "logps/chosen": -244.8084716796875,
      "logps/rejected": -302.7445068359375,
      "loss": 0.2967,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -0.36181896924972534,
      "rewards/margins": 1.2748483419418335,
      "rewards/rejected": -1.636667251586914,
      "step": 80
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.19117271900177,
      "learning_rate": 3.728571428571428e-05,
      "logits/chosen": 2.1426103115081787,
      "logits/rejected": 2.778697967529297,
      "logps/chosen": -246.0666961669922,
      "logps/rejected": -298.4526062011719,
      "loss": 0.2835,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -0.40308842062950134,
      "rewards/margins": 1.4695183038711548,
      "rewards/rejected": -1.872606635093689,
      "step": 90
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 1.2605223655700684,
      "learning_rate": 3.585714285714286e-05,
      "logits/chosen": 2.1329166889190674,
      "logits/rejected": 2.7867610454559326,
      "logps/chosen": -254.50741577148438,
      "logps/rejected": -303.2310791015625,
      "loss": 0.2796,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -0.5631340146064758,
      "rewards/margins": 1.5444176197052002,
      "rewards/rejected": -2.1075515747070312,
      "step": 100
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 1.4136842489242554,
      "learning_rate": 3.442857142857143e-05,
      "logits/chosen": 2.1912379264831543,
      "logits/rejected": 2.881730556488037,
      "logps/chosen": -258.39202880859375,
      "logps/rejected": -319.4632568359375,
      "loss": 0.2304,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -0.6882637143135071,
      "rewards/margins": 1.7262378931045532,
      "rewards/rejected": -2.414501667022705,
      "step": 110
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7430856227874756,
      "learning_rate": 3.3e-05,
      "logits/chosen": 2.8236327171325684,
      "logits/rejected": 3.1668038368225098,
      "logps/chosen": -326.49658203125,
      "logps/rejected": -385.4300842285156,
      "loss": 0.17,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -0.8384100794792175,
      "rewards/margins": 2.177736520767212,
      "rewards/rejected": -3.016146183013916,
      "step": 120
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 1.2423350811004639,
      "learning_rate": 3.1571428571428576e-05,
      "logits/chosen": 2.5608580112457275,
      "logits/rejected": 3.178609848022461,
      "logps/chosen": -296.6634826660156,
      "logps/rejected": -347.92010498046875,
      "loss": 0.2128,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -0.9422613978385925,
      "rewards/margins": 2.2252233028411865,
      "rewards/rejected": -3.167484760284424,
      "step": 130
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 1.7781665325164795,
      "learning_rate": 3.0142857142857146e-05,
      "logits/chosen": 2.089048147201538,
      "logits/rejected": 2.582765579223633,
      "logps/chosen": -238.99539184570312,
      "logps/rejected": -305.5644226074219,
      "loss": 0.2154,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.876325786113739,
      "rewards/margins": 2.325063467025757,
      "rewards/rejected": -3.2013893127441406,
      "step": 140
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9709632992744446,
      "learning_rate": 2.8714285714285716e-05,
      "logits/chosen": 2.1656291484832764,
      "logits/rejected": 2.704251289367676,
      "logps/chosen": -307.7929992675781,
      "logps/rejected": -359.50885009765625,
      "loss": 0.1962,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9857412576675415,
      "rewards/margins": 2.6030120849609375,
      "rewards/rejected": -3.5887534618377686,
      "step": 150
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 4.388927459716797,
      "learning_rate": 2.7285714285714286e-05,
      "logits/chosen": 1.994179129600525,
      "logits/rejected": 2.550208568572998,
      "logps/chosen": -259.3658447265625,
      "logps/rejected": -327.3281555175781,
      "loss": 0.2373,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -1.0809634923934937,
      "rewards/margins": 2.49206805229187,
      "rewards/rejected": -3.5730319023132324,
      "step": 160
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 1.3747289180755615,
      "learning_rate": 2.5857142857142856e-05,
      "logits/chosen": 2.254464864730835,
      "logits/rejected": 3.0980467796325684,
      "logps/chosen": -239.795654296875,
      "logps/rejected": -341.4057312011719,
      "loss": 0.1682,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -1.148428201675415,
      "rewards/margins": 2.7121880054473877,
      "rewards/rejected": -3.8606162071228027,
      "step": 170
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5279175639152527,
      "learning_rate": 2.442857142857143e-05,
      "logits/chosen": 2.5202558040618896,
      "logits/rejected": 3.3541183471679688,
      "logps/chosen": -228.28738403320312,
      "logps/rejected": -330.183837890625,
      "loss": 0.1368,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -1.0542500019073486,
      "rewards/margins": 2.972644329071045,
      "rewards/rejected": -4.026894569396973,
      "step": 180
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 0.6075674891471863,
      "learning_rate": 2.3000000000000003e-05,
      "logits/chosen": 2.2732107639312744,
      "logits/rejected": 3.194065570831299,
      "logps/chosen": -251.3750762939453,
      "logps/rejected": -361.6470947265625,
      "loss": 0.143,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -1.052018404006958,
      "rewards/margins": 3.2222836017608643,
      "rewards/rejected": -4.2743024826049805,
      "step": 190
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 1.5212112665176392,
      "learning_rate": 2.1571428571428574e-05,
      "logits/chosen": 2.159942150115967,
      "logits/rejected": 2.9798717498779297,
      "logps/chosen": -247.7633056640625,
      "logps/rejected": -353.11480712890625,
      "loss": 0.116,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -1.0745751857757568,
      "rewards/margins": 3.2557270526885986,
      "rewards/rejected": -4.3303022384643555,
      "step": 200
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4621155261993408,
      "learning_rate": 2.0142857142857144e-05,
      "logits/chosen": 1.9716432094573975,
      "logits/rejected": 2.810276508331299,
      "logps/chosen": -271.4194641113281,
      "logps/rejected": -380.74713134765625,
      "loss": 0.1364,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -1.4322704076766968,
      "rewards/margins": 3.3517696857452393,
      "rewards/rejected": -4.7840399742126465,
      "step": 210
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 1.0027793645858765,
      "learning_rate": 1.8714285714285714e-05,
      "logits/chosen": 2.0386977195739746,
      "logits/rejected": 2.6578774452209473,
      "logps/chosen": -263.99359130859375,
      "logps/rejected": -355.23199462890625,
      "loss": 0.1249,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -1.1323801279067993,
      "rewards/margins": 3.2944347858428955,
      "rewards/rejected": -4.426815032958984,
      "step": 220
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 2.070904493331909,
      "learning_rate": 1.7285714285714287e-05,
      "logits/chosen": 2.089035987854004,
      "logits/rejected": 2.8179805278778076,
      "logps/chosen": -246.7570343017578,
      "logps/rejected": -336.7355651855469,
      "loss": 0.1564,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -1.2603774070739746,
      "rewards/margins": 3.6765685081481934,
      "rewards/rejected": -4.936945915222168,
      "step": 230
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.9667122960090637,
      "learning_rate": 1.5857142857142857e-05,
      "logits/chosen": 2.1631507873535156,
      "logits/rejected": 2.957785129547119,
      "logps/chosen": -237.52078247070312,
      "logps/rejected": -327.67852783203125,
      "loss": 0.136,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -1.3189431428909302,
      "rewards/margins": 3.519169569015503,
      "rewards/rejected": -4.838112831115723,
      "step": 240
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 1.099435567855835,
      "learning_rate": 1.442857142857143e-05,
      "logits/chosen": 2.467742443084717,
      "logits/rejected": 3.1792874336242676,
      "logps/chosen": -244.92941284179688,
      "logps/rejected": -361.40057373046875,
      "loss": 0.1153,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -1.2961657047271729,
      "rewards/margins": 3.533964157104492,
      "rewards/rejected": -4.830130100250244,
      "step": 250
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 1.1479899883270264,
      "learning_rate": 1.3000000000000001e-05,
      "logits/chosen": 1.8289844989776611,
      "logits/rejected": 2.545846939086914,
      "logps/chosen": -243.72494506835938,
      "logps/rejected": -351.6759338378906,
      "loss": 0.1007,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -1.4074409008026123,
      "rewards/margins": 3.7845776081085205,
      "rewards/rejected": -5.192018508911133,
      "step": 260
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.0176279544830322,
      "learning_rate": 1.1571428571428573e-05,
      "logits/chosen": 2.0757412910461426,
      "logits/rejected": 2.7314813137054443,
      "logps/chosen": -266.37445068359375,
      "logps/rejected": -358.55682373046875,
      "loss": 0.1211,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -1.6578048467636108,
      "rewards/margins": 3.923794984817505,
      "rewards/rejected": -5.581599712371826,
      "step": 270
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 1.85465669631958,
      "learning_rate": 1.0142857142857143e-05,
      "logits/chosen": 2.4375476837158203,
      "logits/rejected": 2.729644775390625,
      "logps/chosen": -290.25457763671875,
      "logps/rejected": -347.98388671875,
      "loss": 0.2066,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -1.6939113140106201,
      "rewards/margins": 3.3604137897491455,
      "rewards/rejected": -5.054325103759766,
      "step": 280
    },
    {
      "epoch": 0.7733333333333333,
      "grad_norm": 0.888825535774231,
      "learning_rate": 8.714285714285715e-06,
      "logits/chosen": 1.989885687828064,
      "logits/rejected": 2.8543975353240967,
      "logps/chosen": -211.8077392578125,
      "logps/rejected": -313.267578125,
      "loss": 0.1403,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -1.4811437129974365,
      "rewards/margins": 3.750865936279297,
      "rewards/rejected": -5.2320098876953125,
      "step": 290
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.3210431337356567,
      "learning_rate": 7.285714285714286e-06,
      "logits/chosen": 2.1330647468566895,
      "logits/rejected": 2.746152877807617,
      "logps/chosen": -245.59658813476562,
      "logps/rejected": -345.2597961425781,
      "loss": 0.1067,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -1.4251638650894165,
      "rewards/margins": 3.88444447517395,
      "rewards/rejected": -5.309607982635498,
      "step": 300
    },
    {
      "epoch": 0.8266666666666667,
      "grad_norm": 1.284128189086914,
      "learning_rate": 5.857142857142857e-06,
      "logits/chosen": 2.098736524581909,
      "logits/rejected": 2.9998691082000732,
      "logps/chosen": -261.6457824707031,
      "logps/rejected": -341.6180114746094,
      "loss": 0.1216,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -1.5779809951782227,
      "rewards/margins": 3.961982250213623,
      "rewards/rejected": -5.539963722229004,
      "step": 310
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 1.132588267326355,
      "learning_rate": 4.571428571428572e-06,
      "logits/chosen": 2.4786667823791504,
      "logits/rejected": 2.7998452186584473,
      "logps/chosen": -282.8229064941406,
      "logps/rejected": -365.9638671875,
      "loss": 0.1171,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -1.650516152381897,
      "rewards/margins": 4.3845930099487305,
      "rewards/rejected": -6.035109043121338,
      "step": 320
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6785863637924194,
      "learning_rate": 3.1428571428571433e-06,
      "logits/chosen": 1.9586092233657837,
      "logits/rejected": 2.654937982559204,
      "logps/chosen": -261.3245849609375,
      "logps/rejected": -352.84759521484375,
      "loss": 0.1256,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -1.5933053493499756,
      "rewards/margins": 4.317269325256348,
      "rewards/rejected": -5.910574913024902,
      "step": 330
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 3.970808744430542,
      "learning_rate": 1.7142857142857145e-06,
      "logits/chosen": 2.468007802963257,
      "logits/rejected": 2.9193978309631348,
      "logps/chosen": -267.4940490722656,
      "logps/rejected": -358.7503967285156,
      "loss": 0.1081,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -1.4975223541259766,
      "rewards/margins": 4.070459365844727,
      "rewards/rejected": -5.567981719970703,
      "step": 340
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 0.5304205417633057,
      "learning_rate": 2.8571428571428575e-07,
      "logits/chosen": 1.9473421573638916,
      "logits/rejected": 2.827683687210083,
      "logps/chosen": -269.8630065917969,
      "logps/rejected": -372.2268981933594,
      "loss": 0.1325,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -1.527345061302185,
      "rewards/margins": 4.525690078735352,
      "rewards/rejected": -6.053035259246826,
      "step": 350
    }
  ],
  "logging_steps": 10,
  "max_steps": 350,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
